以下、**最新テンプレートに LocalAI（無料モデル）の LLMコンテナ を追加した POC 構成**です。

---

## 🧩 `docker-compose.yml`

```yaml
version: "3.9"
services:
  backend:
    build: ./backend
    ports:
      - "8000:8000"
    env_file:
      - .env
    depends_on:
      - db
      - llm

  frontend:
    build: ./frontend
    ports:
      - "3000:3000"
    env_file:
      - .env
    depends_on:
      - backend

  db:
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: changethis
      POSTGRES_DB: mydb
    volumes:
      - pgdata:/var/lib/postgresql/data

  llm:
    image: localai/localai:latest-aio-cpu
    ports:
      - "8080:8080"
    volumes:
      - ./models:/models
    command: ["--models-path", "/models"]
    # 全て無料・CPU対応可能なAIOイメージです :contentReference[oaicite:1]{index=1}

volumes:
  pgdata:
```

---

## 🛠 `backend/Dockerfile`

```dockerfile
FROM python:3.11-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY ./app ./app
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

* FastAPI を独自構築。軽量かつ推奨アプローチ&#x20;

---

## 🧩 ディレクトリ構造（tree）

```text
my-poc/
├── docker-compose.yml           # コンテナ構成（backend/frontend/db/llm）
├── .env                         # DB_URL, LLM_URL, 環境変数
├── models/                      # LocalAI用モデル置き場
├── backend/
│   ├── Dockerfile              # FastAPI用
│   ├── requirements.txt
│   └── app/
│       ├── main.py             # FastAPIインスタンス初期化
│       ├── api/
│       │   ├── generative.py   # 問題生成エンドポイント (`/generate-question`) - LLM呼び出し含む
│       │   └── grader.py       # 回答採点エンドポイント (`/submit-sql`) - DB実行＋結果比較＋解説
│       ├── core/
│       │   ├── db.py           # PostgreSQL接続管理（asyncpg or SQLModel）
│       │   └── models.py       # 正解SQL等保存用スキーマ定義
│       └── schemas.py          # Pydantic 入出力モデル定義
└── frontend/
    ├── Dockerfile              # Next.js or React 開発環境
    ├── package.json
    └── src/ or pages/
        ├── index.tsx          # 問題取得 → テキスト表示 + SQL入力フォーム
        └── result.tsx         # 結果受信 → 正誤判定 + 解説表示
```

---

## 📌 各ファイルの目的と機能

* **docker-compose.yml**

  * 4つのサービス（backend/frontend/db/llm）を定義し相互接続
  * LocalAI による LLM 層を実装し、OpenAI 形式 API 提供

* **backend/Dockerfile**

  * Python 3.11 を利用し、FastAPI を軽量に実装
  * `uvicorn` でサーバ起動構成

* **app/main.py**

  * FastAPI 起動、CORS 設定、ルーター統合

* **app/api/generative.py**

  * `/generate-question`：DB スキーマとサンプルデータを読み取り、LLM に投げて自然言語問題＋正解SQLを生成

* **app/api/grader.py**

  * `/submit-sql`：ユーザーSQLを DB 実行し、正解SQL 結果と比較。違いがあれば再度 LLM に差分解説を生成

* **app/core/db.py**

  * asyncpg または SQLModel で非同期 DB 接続 + 初回スキーマ／テーブル作成

* **app/core/models.py**

  * SQLModelなどで問題／正解保存スキーマ定義

* **app/schemas.py**

  * Pydantic 入力・出力モデル定義（Clean 層）

* **frontend/index.tsx**

  * 問題取得ボタン、問題文表示、SQL テキスト入力欄、送信ボタン UI

* **frontend/result.tsx**

  * FastAPI `/submit-sql` 結果を受け取り、テーブル結果・正誤可視化・解説表示

---

## ✅ 要件定義まとめ

| 層          | ファイル/機能                   | 要件                                             |
| ---------- | ------------------------- | ---------------------------------------------- |
| **コンテナ構成** | docker-compose.yml        | FastAPI/API/API+LLM統合/db/LocalAI 無料モデル起動（CPU可） |
| **バックエンド** | generative.py / grader.py | LLM投げ→SQL生成／検証→採点＋解説生成                         |
| **DB 層**   | db.py / models.py         | PostgreSQL操作／SQL実行／スキーマ管理                      |
| **フロント**   | index.tsx / result.tsx    | UI描画（問題 → 入力 → 表示）                             |

POCとしての**最小限かつ完全な開発フロー**に対応する構成です。
この設計で進めてよろしければ、即セットアップ・動作確認の次ステップへ移行できます😊
